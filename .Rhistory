# Detect available cores
num_cores <- detectCores()
# Create a cluster and register it
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Run parallel computation with a fixed seed per iteration
result <- foreach(i = 1:3, .combine = c) %dopar% {
random_function(i)
}
# Stop the cluster
stopCluster(cl)
print(result)
library(doParallel)
random_function <- function(i) {
set.seed(123 + i)
runif(1)
}
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Run parallel computation with a fixed seed per iteration
result <- foreach(i = 1:3) %dopar% {
random_function(i)
}
# Stop the cluster
stopCluster(cl)
print(result)
library(doParallel)
random_function <- function(i) {
set.seed(123 + i)
runif(1)
}
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Run parallel computation with a fixed seed per iteration
result <- foreach(i = 1:3) %dopar% {
random_function(i)
}
# Stop the cluster
stopCluster(cl)
print(result)
library(doParallel)
random_function <- function(i) {
set.seed(123 + i)
runif(1)
}
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
result <- foreach(i = 1:3, .combine = c) %dopar% {
random_function(i)
}
stopCluster(cl)
print(result)
library(doParallel)
# Define a computationally expensive function
expensive_function <- function(i) {
set.seed(123 + i)  # Fix seed for reproducibility
sum(runif(10^6))   # Sum of 1 million random numbers
}
# -----------------------
# 1. Run Without Parallelization
# -----------------------
start_time_seq <- Sys.time()
result_seq <- sapply(1:10, expensive_function)
end_time_seq <- Sys.time()
time_seq <- end_time_seq - start_time_seq
print(paste("Sequential Execution Time:", time_seq))
# -----------------------
# 2. Run With Parallelization
# -----------------------
num_cores <- detectCores() - 1  # Use all but one core
cl <- makeCluster(num_cores)
registerDoParallel(cl)
start_time_par <- Sys.time()
result_par <- foreach(i = 1:10, .combine = c, .packages = "base") %dopar% {
expensive_function(i)
}
end_time_par <- Sys.time()
stopCluster(cl)
time_par <- end_time_par - start_time_par
print(paste("Parallel Execution Time:", time_par))
library(doParallel)
expensive_function <- function(i) {
set.seed(123 + i)  # Fix seed
sum(runif(10^6))
}
# -----------------------
# 1. Run Without Parallelization
# -----------------------
start_time_seq <- Sys.time()
result_seq <- sapply(1:10, expensive_function)
end_time_seq <- Sys.time()
time_seq <- end_time_seq - start_time_seq
print(paste("Sequential Execution Time:", time_seq))
# -----------------------
# 2. Run With Parallelization
# -----------------------
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
start_time_par <- Sys.time()
result_par <- foreach(i = 1:10, .combine = c, .packages = "base") %dopar% {
expensive_function(i)
}
end_time_par <- Sys.time()
stopCluster(cl)
time_par <- end_time_par - start_time_par
print(paste("Parallel Execution Time:", time_par))
library(rTensor)
library(doParallel)
library(foreach)
# Define CP decomposition function with a fixed seed
cp_decomp <- function() {
set.seed(123)  # Fix seed for reproducibility
tensor_data <- array(runif(4 * 5 * 6), dim = c(4, 5, 6))  # Create a tensor
tensor <- as.tensor(tensor_data)
cp(tensor, num_components = 3)  # Perform CP decomposition
}
# ----------------------
# 1. Sequential Execution
# ----------------------
start_time_seq <- Sys.time()
result_seq <- cp_decomp()  # Run sequentially
end_time_seq <- Sys.time()
time_seq <- end_time_seq - start_time_seq
print(paste("Sequential Execution Time:", time_seq))
# ----------------------
# 2. Parallel Execution
# ----------------------
num_cores <- detectCores() - 1  # Use all but one core
cl <- makeCluster(num_cores)
registerDoParallel(cl)
start_time_par <- Sys.time()
# Perform CP decomposition in parallel
result_par <- foreach(i = 1:10, .packages = "rTensor") %dopar% {
cp_decomp()
}
end_time_par <- Sys.time()
stopCluster(cl)
time_par <- end_time_par - start_time_par
print(paste("Parallel Execution Time:", time_par))
# ----------------------
# 3. Verify Results are Identical
# ----------------------
identical_result <- identical(result_seq, result_par[[1]])  # Compare first parallel result with sequential
print(paste("Are results identical?", identical_result))
# Define CP decomposition function with a fixed seed
# Define CP decomposition function with a fixed seed
cp_decomp <- function(i) {
set.seed(123 + i)  # Fix seed per iteration
tensor_data <- array(runif(4 * 5 * 6), dim = c(4, 5, 6))  # Create a tensor
tensor <- as.tensor(tensor_data)
cp(tensor, num_components = 3)  # Perform CP decomposition
}
# Number of times to run CP decomposition
num_runs <- 10
# ----------------------
# 1. Sequential Execution (Fair Comparison)
# ----------------------
start_time_seq <- Sys.time()
result_seq <- lapply(1:num_runs, cp_decomp)  # Run the same number of times as parallel
end_time_seq <- Sys.time()
time_seq <- end_time_seq - start_time_seq
print(paste("Sequential Execution Time:", time_seq))
# ----------------------
# 2. Parallel Execution
# ----------------------
num_cores <- detectCores() - 1  # Use all but one core
cl <- makeCluster(num_cores)
registerDoParallel(cl)
start_time_par <- Sys.time()
# Perform CP decomposition in parallel
result_par <- foreach(i = 1:num_runs, .packages = "rTensor") %dopar% {
cp_decomp(i)
}
end_time_par <- Sys.time()
stopCluster(cl)
time_par <- end_time_par - start_time_par
print(paste("Parallel Execution Time:", time_par))
# ----------------------
# 3. Verify Results are Identical
# ----------------------
identical_results <- all(mapply(identical, result_seq, result_par))  # Compare all results
print(paste("identical", identical_results))
update
parallel::detectCores()
library(doParallel)
library(foreach)
# Number of tasks
n_tasks <- 100
# Simulated workload function (slow on purpose)
simulate_work <- function(i) {
A <- matrix(rnorm(1000), 50, 20)
B <- matrix(rnorm(1000), 20, 50)
Sys.sleep(0.05)  # simulate 50ms delay
sum(A %*% B)
}
# --- Serial execution ---
cat("Running in serial...\n")
t1 <- Sys.time()
serial_results <- sapply(1:n_tasks, simulate_work)
t2 <- Sys.time()
serial_time <- as.numeric(difftime(t2, t1, units = "secs"))
cat(sprintf("Serial time: %.2f seconds\n\n", serial_time))
# --- Parallel execution ---
cat("Running in parallel...\n")
n_cores <- max(1, detectCores() - 2)
cl <- makeCluster(n_cores)
registerDoParallel(cl)
t3 <- Sys.time()
parallel_results <- foreach(i = 1:n_tasks, .combine = c) %dopar% {
simulate_work(i)
}
t4 <- Sys.time()
parallel_time <- as.numeric(difftime(t4, t3, units = "secs"))
cat(sprintf("Parallel time with %d cores: %.2f seconds\n", n_cores, parallel_time))
stopCluster(cl)
# --- Speedup report ---
speedup <- serial_time / parallel_time
cat(sprintf("\nSpeedup: %.2fx faster with parallel\n", speedup))
setwd("C:/Users/yh95l/Desktop/CMTE")
#setwd("~/Desktop/CMTE")
library(foreach)
library(doParallel)
library("TRES")
unlink(list.files("Data", full.names = TRUE), recursive = TRUE, force = TRUE)
file.remove(list.files("results", full.names = TRUE))
# Define parameter lists
r_vec_list <- list(c(10,10), c(50,50), c(100,100))
r_vec_list <- list(c(10,10), c(50,50))
p_list     <- c(3)
eps_list   <- c(0.1)
n_list     <- c(50, 100, 200, 500)
#n_list     <- c(50, 100)
Omega_list <- c(3)
f_num_list <- c(1, 2, 3)
#f_num_list <- c(2, 3)
n_rep      <- 10
for (n_dir in 1:5) {
cat(sprintf("=== [%s] Running for n_dir = %d ===\n", Sys.time(), n_dir))
param_grid <- expand.grid(
r_index = seq_along(r_vec_list),
p       = p_list,
eps     = eps_list,
n       = n_list,
Omega_c = Omega_list,
f_num   = f_num_list,
n_dir   = n_dir
)
source("./DataGen.R")
source("./Evaluation.R")
cat(sprintf("=== [%s] Running CMTE ===\n", Sys.time()))
source("./alg_CMTE/cmte_exp.R")
cat(sprintf("=== [%s] Running TRR ===\n", Sys.time()))
source("./alg_TRR/trr_exp.R")
cat(sprintf("=== [%s] Running TMDDM ===\n", Sys.time()))
source("./alg_TMDDM/tmddm_exp.R")
# Cleanup Data
unlink(list.files("Data", full.names = TRUE), recursive = TRUE, force = TRUE)
}
#generate table
source("./table_output.R")
setwd("C:/Users/yh95l/Desktop/CMTE")
#setwd("~/Desktop/CMTE")
library(foreach)
library(doParallel)
library("TRES")
unlink(list.files("Data", full.names = TRUE), recursive = TRUE, force = TRUE)
file.remove(list.files("results", full.names = TRUE))
# Define parameter lists
r_vec_list <- list(c(10,10), c(50,50), c(100,100))
#r_vec_list <- list(c(10,10), c(50,50))
p_list     <- c(3)
eps_list   <- c(0.1)
n_list     <- c(50, 100, 200, 500)
#n_list     <- c(50, 100)
Omega_list <- c(3)
f_num_list <- c(1, 2, 3)
#f_num_list <- c(2, 3)
n_rep      <- 20
source("./Evaluation.R")
for (n_dir in 3:5) {
# Cleanup Data
unlink(list.files("Data", full.names = TRUE), recursive = TRUE, force = TRUE)
cat(sprintf("=== [%s] Running for n_dir = %d ===\n", Sys.time(), n_dir))
param_grid <- expand.grid(
r_index = seq_along(r_vec_list),
p       = p_list,
eps     = eps_list,
n       = n_list,
Omega_c = Omega_list,
f_num   = f_num_list,
n_dir   = n_dir
)
source("./DataGen.R")
cat(sprintf("=== [%s] Running CMTE ===\n", Sys.time()))
source("./alg_CMTE/cmte_exp.R")
cat(sprintf("=== [%s] Running TRR ===\n", Sys.time()))
source("./alg_TRR/trr_exp.R")
cat(sprintf("=== [%s] Running TMDDM ===\n", Sys.time()))
source("./alg_TMDDM/tmddm_exp.R")
}
#generate table
source("./table_output.R")
n_dir_list <- c(3,4,5)
# combinations
param_grid <- expand.grid(
r_index = seq_along(r_vec_list),
p = p_list,
eps = eps_list,
n = n_list,
Omega_c = Omega_list,
f_num = f_num_list,
n_dir = n_dir_list
)
#generate table
source("./table_output.R")
methods <- c("CMTE-ECD", "TRR-ECD", "TMDDM")
best_counts <- setNames(rep(0, length(methods)), methods)
total_groups <- 0
for (i in 1:nrow(param_grid)) {
r_vec <- r_vec_list[[param_grid$r_index[i]]]
p     <- param_grid$p[i]
eps   <- param_grid$eps[i]
n     <- param_grid$n[i]
f_num <- param_grid$f_num[i]
n_dir <- param_grid$n_dir[i]
r_str <- paste(r_vec, collapse = "x")
file_cmte  <- sprintf("results/coef_est_cmte_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
file_trr   <- sprintf("results/coef_est_trr_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
file_tmddm <- sprintf("results/coef_est_tmddm_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
acc_map <- list()
if (file.exists(file_cmte)) {
env <- new.env(); load(file_cmte, envir = env)
acc_map[["CMTE-ECD"]] <- round(unlist(env$cmte_ecd_acc_list), 4)
}
if (file.exists(file_trr)) {
env <- new.env(); load(file_trr, envir = env)
acc_map[["TRR-ECD"]] <- round(unlist(env$trr_ecd_acc_list), 4)
}
if (file.exists(file_tmddm)) {
env <- new.env(); load(file_tmddm, envir = env)
acc_map[["TMDDM"]] <- round(unlist(env$tmddm_acc_list), 4)
}
if (length(acc_map) < 2) next  # Skip if fewer than 2 methods available
acc_matrix <- do.call(rbind, acc_map)
total_dist <- rowSums(acc_matrix, na.rm = TRUE)
best_method <- names(which.min(total_dist))
best_counts[best_method] <- best_counts[best_method] + 1
total_groups <- total_groups + 1
}
# Convert to percentage
best_percentage <- round(100 * best_counts / total_groups, 1)
result_df <- data.frame(Method = names(best_percentage),
Best_Performance_Percentage = as.numeric(best_percentage))
print(result_df)
methods <- c("CMTE-ECD", "TRR-ECD", "TMDDM")
counts_f1 <- setNames(rep(0, length(methods)), methods)
counts_not_f1 <- setNames(rep(0, length(methods)), methods)
total_f1 <- 0
total_not_f1 <- 0
for (i in 1:nrow(param_grid)) {
r_vec <- r_vec_list[[param_grid$r_index[i]]]
p     <- param_grid$p[i]
eps   <- param_grid$eps[i]
n     <- param_grid$n[i]
f_num <- param_grid$f_num[i]
n_dir <- param_grid$n_dir[i]
r_str <- paste(r_vec, collapse = "x")
file_cmte  <- sprintf("results/coef_est_cmte_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
file_trr   <- sprintf("results/coef_est_trr_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
file_tmddm <- sprintf("results/coef_est_tmddm_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
acc_map <- list()
if (file.exists(file_cmte)) {
env <- new.env(); load(file_cmte, envir = env)
acc_map[["CMTE-ECD"]] <- round(unlist(env$cmte_ecd_acc_list), 4)
}
if (file.exists(file_trr)) {
env <- new.env(); load(file_trr, envir = env)
acc_map[["TRR-ECD"]] <- round(unlist(env$trr_ecd_acc_list), 4)
}
if (file.exists(file_tmddm)) {
env <- new.env(); load(file_tmddm, envir = env)
acc_map[["TMDDM"]] <- round(unlist(env$tmddm_acc_list), 4)
}
if (length(acc_map) < 2) next  # Skip if fewer than 2 methods available
acc_matrix <- do.call(rbind, acc_map)
total_dist <- rowSums(acc_matrix, na.rm = TRUE)
best_method <- names(which.min(total_dist))
if (f_num == 1) {
counts_f1[best_method] <- counts_f1[best_method] + 1
total_f1 <- total_f1 + 1
} else {
counts_not_f1[best_method] <- counts_not_f1[best_method] + 1
total_not_f1 <- total_not_f1 + 1
}
}
# Convert to percentage
percent_f1 <- round(100 * counts_f1 / total_f1, 1)
percent_not_f1 <- round(100 * counts_not_f1 / total_not_f1, 1)
# Combine into a data frame
result_df <- data.frame(
Method = methods,
Percent_f_num_1 = percent_f1,
Percent_f_num_not_1 = percent_not_f1
)
print(result_df)
methods <- c("CMTE-ECD", "TRR-ECD", "TMDDM")
f_nums <- sort(unique(param_grid$f_num))
count_table <- matrix(0, nrow = length(methods), ncol = length(f_nums),
dimnames = list(methods, paste0("f", f_nums)))
total_counts <- setNames(rep(0, length(f_nums)), paste0("f", f_nums))
for (i in 1:nrow(param_grid)) {
r_vec <- r_vec_list[[param_grid$r_index[i]]]
p     <- param_grid$p[i]
eps   <- param_grid$eps[i]
n     <- param_grid$n[i]
f_num <- param_grid$f_num[i]
n_dir <- param_grid$n_dir[i]
r_str <- paste(r_vec, collapse = "x")
f_key <- paste0("f", f_num)
file_cmte  <- sprintf("results/coef_est_cmte_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
file_trr   <- sprintf("results/coef_est_trr_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
file_tmddm <- sprintf("results/coef_est_tmddm_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
acc_map <- list()
if (file.exists(file_cmte)) {
env <- new.env(); load(file_cmte, envir = env)
acc_map[["CMTE-ECD"]] <- round(unlist(env$cmte_ecd_acc_list), 4)
}
if (file.exists(file_trr)) {
env <- new.env(); load(file_trr, envir = env)
acc_map[["TRR-ECD"]] <- round(unlist(env$trr_ecd_acc_list), 4)
}
if (file.exists(file_tmddm)) {
env <- new.env(); load(file_tmddm, envir = env)
acc_map[["TMDDM"]] <- round(unlist(env$tmddm_acc_list), 4)
}
if (length(acc_map) < 2) next
acc_matrix <- do.call(rbind, acc_map)
total_dist <- rowSums(acc_matrix, na.rm = TRUE)
best_method <- names(which.min(total_dist))
count_table[best_method, f_key] <- count_table[best_method, f_key] + 1
total_counts[f_key] <- total_counts[f_key] + 1
}
# Convert to percentages
percent_table <- sweep(count_table, 2, total_counts, FUN = "/") * 100
percent_table <- round(percent_table, 1)
# Convert to data frame for display
percent_df <- as.data.frame(percent_table)
percent_df$Method <- rownames(percent_table)
percent_df <- percent_df[, c("Method", paste0("f", f_nums))]
print(percent_df)
methods <- c("CMTE-ECD", "TRR-ECD", "TMDDM")
# Create a key for each (n_dir, f_num) combo
group_keys <- unique(paste0("dir", param_grid$n_dir, "_f", param_grid$f_num))
count_table <- matrix(0, nrow = length(methods), ncol = length(group_keys),
dimnames = list(methods, group_keys))
total_counts <- setNames(rep(0, length(group_keys)), group_keys)
for (i in 1:nrow(param_grid)) {
r_vec <- r_vec_list[[param_grid$r_index[i]]]
p     <- param_grid$p[i]
eps   <- param_grid$eps[i]
n     <- param_grid$n[i]
f_num <- param_grid$f_num[i]
n_dir <- param_grid$n_dir[i]
r_str <- paste(r_vec, collapse = "x")
group_key <- paste0("dir", n_dir, "_f", f_num)
file_cmte  <- sprintf("results/coef_est_cmte_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
file_trr   <- sprintf("results/coef_est_trr_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
file_tmddm <- sprintf("results/coef_est_tmddm_n%d_p%d_r%s_eps%.2f_fn%d_dir%d_rep%d.RData",
n, p, r_str, eps, f_num, n_dir, n_rep)
acc_map <- list()
if (file.exists(file_cmte)) {
env <- new.env(); load(file_cmte, envir = env)
acc_map[["CMTE-ECD"]] <- round(unlist(env$cmte_ecd_acc_list), 4)
}
if (file.exists(file_trr)) {
env <- new.env(); load(file_trr, envir = env)
acc_map[["TRR-ECD"]] <- round(unlist(env$trr_ecd_acc_list), 4)
}
if (file.exists(file_tmddm)) {
env <- new.env(); load(file_tmddm, envir = env)
acc_map[["TMDDM"]] <- round(unlist(env$tmddm_acc_list), 4)
}
if (length(acc_map) < 2) next
acc_matrix <- do.call(rbind, acc_map)
total_dist <- rowSums(acc_matrix, na.rm = TRUE)
best_method <- names(which.min(total_dist))
count_table[best_method, group_key] <- count_table[best_method, group_key] + 1
total_counts[group_key] <- total_counts[group_key] + 1
}
# Convert to percentages
percent_table <- sweep(count_table, 2, total_counts, FUN = "/") * 100
percent_table <- round(percent_table, 1)
# Convert to data frame
percent_df <- as.data.frame(percent_table)
percent_df$Method <- rownames(percent_table)
percent_df <- percent_df[, c("Method", colnames(percent_table))]
print(percent_df)
